# gui/project_description.py

description = """
# ğŸ“– Projektbeschreibung

## Datenbeschaffung & Vorbereitung
- Ausgangspunkt war **Zensus-Datensatz 0004**, der die ersten GebÃ¤udedaten enthielt.  
- Bald stellte sich heraus, dass **0004 redundant** zur Spalte *Insgesamt* von **0005** war â†’ daher entfernt.  
- AnschlieÃŸend kam **0005** (Baujahre) als Kernbasis, ergÃ¤nzt um weitere DatensÃ¤tze.  
- Dabei stellte sich heraus, dass **einige Inserate fehlerhafte Angaben** hatten (z. B. FlÃ¤chen 0 oder unrealistisch hohe Mieten) â†’ wurden bereinigt.  
- Ein besonderes Thema war das **Mapping von Standorten**: GKZ, AGS, PLZ, Bundesland, Gemeindenamen.  
  - Problem: Schreibvarianten wie *St.*, *Bad*, *kreisfreie Stadt*, Ortsteile.  
  - LÃ¶sung: Normalisierung und Mapping auf die Spalte **ARS** (eindeutiger Identifier).  

## Datenbereinigung
- Nicht plausible Werte entfernt.  
- Nur Kerneigenschaften behalten: `area_sqm`, `rooms`, `floor`, `heatingType`, etc.  
- Nach der Bereinigung reduzierte sich die Datenmenge deutlich, **Trainingszeit ging von 15 Minuten auf wenige Sekunden**.  

## Machine Learning
- Modell: **RandomForestRegressor** (scikit-learn).  
- Warum RandomForest?
  - robust bei gemischten Features (kategorisch + numerisch)
  - gute Performance ohne viel Hyperparameter-Tuning
  - liefert Feature Importances (Interpretierbarkeit)  
- Features: GrÃ¶ÃŸe, Zimmer, Stockwerk, Baujahr-Periode (aus Zensus), Ausstattung (Lift, KÃ¼che, Garten), Region (ARS).  
- Output: **geschÃ¤tzte Nettokaltmiete (â‚¬)**.  
- Ergebnisse:
  - MAE â‰ˆ 54 â‚¬  
  - MdAE â‰ˆ 15 â‚¬  
  - RÂ² â‰ˆ 0.84  

## App (Streamlit)
- Stammdaten zu **EigentÃ¼mern, Objekten, Mietern** werden erfasst.  
- Speicherung erfolgt in einer **SQLite-Datenbank**.  
- VertrÃ¤ge und Zahlungen kÃ¶nnen dokumentiert werden.  
- **Mietpreis-Vorschlag** nutzt das trainierte Modell.  
- ZusÃ¤tzlich gibt es eine Funktion fÃ¼r **Dokumentenerstellung (Mahnschreiben)** mit optionaler LLM-Verbesserung.  

## Herausforderungen
- Komplexes Mapping der Standorte.  
- Konsistenz zwischen Zensus-Daten und Immobilien-Inseraten.  
- DatenqualitÃ¤t (falsche Inserate).  
- Sicherstellen, dass das Training auch reproduzierbar lÃ¤uft.  

## Fazit
- Projekt bildet einen **End-to-End-Data-Science-Prozess** ab: von Datenbeschaffung â†’ Bereinigung â†’ Feature Engineering â†’ Modelltraining â†’ Deployment (Streamlit-App).  
- NÃ¤chste Schritte: weitere ML-Modelle testen (XGBoost, LightGBM), mehr InteraktivitÃ¤t im Dashboard, Integration zusÃ¤tzlicher Datenquellen (z. B. Energieverbrauch, Demografie).  
"""
